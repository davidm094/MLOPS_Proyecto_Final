# MLOps Proyecto Final - End-to-End Kubernetes Platform

Este repositorio contiene la implementaciÃ³n completa de una plataforma MLOps End-to-End desplegada sobre Kubernetes (K3d) y gestionada vÃ­a GitOps con Argo CD.

## ğŸ— Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              K3d Cluster                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Argo CD   â”‚  â”‚   Airflow   â”‚  â”‚   MLflow    â”‚  â”‚  SeaweedFS  â”‚        â”‚
â”‚  â”‚  (GitOps)   â”‚  â”‚ (Pipelines) â”‚  â”‚ (Tracking)  â”‚  â”‚    (S3)     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚         â”‚                â”‚                â”‚                â”‚                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                   â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚   FastAPI   â”‚  â”‚  Streamlit  â”‚â”‚  â”‚ PostgreSQL  â”‚                        â”‚
â”‚  â”‚    (API)    â”‚  â”‚ (Frontend)  â”‚â”‚  â”‚  (Metadata) â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Infraestructura
- **Kubernetes:** K3d (K3s en Docker) - Ideal para desarrollo local
- **GitOps:** Argo CD (Continuous Deployment desde Git)
- **Storage:** SeaweedFS (S3-compatible) + PostgreSQL
- **Networking:** NodePort Services

### Componentes MLOps
- **OrquestaciÃ³n:** Apache Airflow con KubernetesExecutor y Git-Sync
- **Experiment Tracking:** MLflow (Backend: Postgres, Artifacts: SeaweedFS S3)
- **Model Serving:** FastAPI con endpoints de predicciÃ³n y explicabilidad
- **Interpretabilidad:** SHAP TreeExplainer para explicaciones de predicciones
- **Frontend:** Streamlit con visualizaciones interactivas
- **CI/CD:** GitHub Actions para build y push de imÃ¡genes Docker

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos
- Docker Desktop (Windows/macOS) o Docker Engine (Linux)
- WSL2 (si estÃ¡s en Windows)
- kubectl instalado
- 8GB RAM mÃ­nimo, 16GB recomendado
- 20GB de espacio en disco

### Despliegue Automatizado

```bash
# 1. Clonar el repositorio
git clone https://github.com/davidm094/MLOPS_Proyecto_Final.git
cd MLOPS_Proyecto_Final

# 2. Dar permisos de ejecuciÃ³n a los scripts
chmod +x scripts/*.sh

# 3. Ejecutar el despliegue completo
./scripts/start_mlops.sh
```

**Tiempo estimado:** 5-7 minutos

Este script:
1. âœ… Crea un cluster K3d con puertos mapeados
2. âœ… Instala y configura Argo CD
3. âœ… Despliega toda la infraestructura (Postgres, SeaweedFS)
4. âœ… Despliega las aplicaciones MLOps (Airflow, MLflow, API, Frontend)
5. âœ… Crea buckets S3 necesarios
6. âœ… Muestra las URLs de acceso y credenciales

## ğŸŒ Acceso a Servicios

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Argo CD** | http://localhost:30443 | admin / (ver comando abajo) |
| **Airflow** | http://localhost:30080 | admin / admin |
| **MLflow** | http://localhost:30500 | - |
| **API (FastAPI)** | http://localhost:30800 | - |
| **Frontend (Streamlit)** | http://localhost:30501 | - |

### Obtener Password de Argo CD
```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d && echo
```

## ğŸ¤– Pipeline de Machine Learning

### Flujo del DAG
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    start     â”‚â”€â”€â”€â–¶â”‚ ingest_data  â”‚â”€â”€â”€â–¶â”‚ check_drift  â”‚â”€â”€â”€â–¶â”‚ train_model  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚                    â”‚
                                               â”‚ (no drift)         â”‚
                                               â–¼                    â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚ end_pipeline â”‚â—€â”€â”€â”€â”‚ end_pipeline â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DescripciÃ³n de Tareas

| Tarea | DescripciÃ³n |
|-------|-------------|
| `ingest_data` | Descarga datos de API externa, guarda en S3 |
| `check_drift` | Compara datos actuales vs referencia (KS-test) |
| `train_model` | Entrena RandomForest, registra en MLflow con SHAP |
| `end_pipeline` | Marca finalizaciÃ³n del pipeline |

### Modelo y Features

- **Algoritmo:** Random Forest Regressor
- **Target:** Precio de propiedades inmobiliarias
- **Features utilizadas:**
  - `bed` - NÃºmero de habitaciones
  - `bath` - NÃºmero de baÃ±os
  - `acre_lot` - TamaÃ±o del lote (acres)
  - `house_size` - TamaÃ±o de la casa (sqft)

### MÃ©tricas Registradas
- **RMSE:** Root Mean Squared Error (~$1.4M)
- **RÂ²:** Coeficiente de determinaciÃ³n

## ğŸ” Explicabilidad con SHAP

### Â¿QuÃ© es SHAP?
SHAP (SHapley Additive exPlanations) es una tÃ©cnica que explica las predicciones de modelos ML asignando a cada feature un valor de importancia para cada predicciÃ³n individual.

### ImplementaciÃ³n

1. **Durante el entrenamiento:**
   - Se genera un `TreeExplainer` para el modelo RandomForest
   - Se guarda como artefacto `explainer.pkl` en MLflow/S3

2. **En la API (`/explain`):**
   - Carga el explainer desde S3
   - Calcula SHAP values para la entrada
   - Retorna valores, base value y nombres de features

3. **En el Frontend:**
   - Visualiza un grÃ¡fico de barras con contribuciones
   - Muestra tabla detallada de impacto por feature
   - Indica direcciÃ³n del impacto (aumenta/disminuye precio)

### Ejemplo de Respuesta `/explain`
```json
{
  "price": 350000.0,
  "shap_values": [15000.5, -8000.2, 5000.0, 25000.8],
  "base_value": 312999.9,
  "feature_names": ["bed", "bath", "acre_lot", "house_size"],
  "feature_values": [3.0, 2.0, 0.25, 1800.0]
}
```

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ dags/                 # DAGs de Airflow
â”‚   â”‚   â”‚   â”œâ”€â”€ mlops_pipeline.py # DAG principal
â”‚   â”‚   â”‚   â””â”€â”€ src/              # Scripts de ML
â”‚   â”‚   â”‚       â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”‚       â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”‚       â”œâ”€â”€ drift_detection.py
â”‚   â”‚   â”‚       â””â”€â”€ model_training.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ src/main.py           # FastAPI con /predict y /explain
â”‚   â”‚   â”œâ”€â”€ k8s/deployment.yaml
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ src/app.py            # Streamlit con SHAP visualization
â”‚       â”œâ”€â”€ k8s/deployment.yaml
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ argocd/
â”‚   â”‚   â”œâ”€â”€ applications/
â”‚   â”‚   â”‚   â””â”€â”€ core-apps.yaml    # Todas las aplicaciones Argo CD
â”‚   â”‚   â””â”€â”€ install/
â”‚   â”‚       â””â”€â”€ install.yaml      # Manifiestos de Argo CD
â”‚   â””â”€â”€ manifests/
â”‚       â”œâ”€â”€ services/             # NodePort services
â”‚       â””â”€â”€ setup/                # Jobs de inicializaciÃ³n
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_mlops.sh            # ğŸš€ Script principal
â”‚   â”œâ”€â”€ create_cluster.sh
â”‚   â””â”€â”€ bootstrap_argocd.sh
â”œâ”€â”€ DEPLOYMENT_LOG.md             # BitÃ¡cora detallada
â””â”€â”€ README.md
```

## ğŸ§ª Testing del Pipeline

### 1. Ejecutar el DAG manualmente

```bash
# Trigger desde CLI
kubectl exec -n mlops $(kubectl get pods -n mlops -l component=scheduler -o jsonpath="{.items[0].metadata.name}") \
  -c scheduler -- airflow dags trigger mlops_full_pipeline
```

O desde la UI de Airflow: http://localhost:30080

### 2. Probar la API

```bash
# PredicciÃ³n
curl -X POST http://localhost:30800/predict \
  -H "Content-Type: application/json" \
  -d '{"bed": 3, "bath": 2, "acre_lot": 0.25, "house_size": 1800}'

# ExplicaciÃ³n SHAP
curl -X POST http://localhost:30800/explain \
  -H "Content-Type: application/json" \
  -d '{"bed": 3, "bath": 2, "acre_lot": 0.25, "house_size": 1800}'

# Health check
curl http://localhost:30800/health

# Recargar modelo
curl -X POST http://localhost:30800/reload
```

### 3. Usar el Frontend

1. Acceder a http://localhost:30501
2. Tab "Predict Price": Llenar formulario y obtener predicciÃ³n
3. Tab "SHAP Explanation": Ver contribuciÃ³n de cada feature
4. Tab "Model Info": Ver estado del modelo y mÃ©tricas

## ğŸ›  Comandos Ãštiles

### GestiÃ³n del Cluster
```bash
# Ver todos los pods
kubectl get pods -A

# Ver aplicaciones de Argo CD
kubectl get apps -n argocd

# Logs del scheduler de Airflow
kubectl logs -n mlops -l component=scheduler -c scheduler -f

# Logs de MLflow
kubectl logs -n mlops -l app.kubernetes.io/name=mlflow -f

# Detener cluster (conserva datos)
k3d cluster stop mlops-cluster

# Eliminar cluster
k3d cluster delete mlops-cluster
```

### Debugging
```bash
# Shell en un pod
kubectl exec -it <pod-name> -n mlops -- /bin/bash

# Ver eventos recientes
kubectl get events -n mlops --sort-by='.lastTimestamp' | tail -20

# Describir pod problemÃ¡tico
kubectl describe pod <pod-name> -n mlops

# Ver datos en S3
kubectl exec -n mlops <scheduler-pod> -c scheduler -- python3 -c "
import boto3
s3 = boto3.client('s3', endpoint_url='http://seaweedfs-s3.mlops.svc:8333', 
                  aws_access_key_id='any', aws_secret_access_key='any')
for bucket in s3.list_buckets()['Buckets']:
    print(bucket['Name'])
"
```

## ğŸ”„ CI/CD Pipeline

### GitHub Actions
El workflow `.github/workflows/ci.yaml` se ejecuta en cada push a `main`:

1. Build de imÃ¡genes Docker (airflow, api, frontend)
2. Tag con `github.sha` y `latest`
3. Push a Docker Hub

### ConfiguraciÃ³n de Secretos
En GitHub â†’ Settings â†’ Secrets:
- `DOCKERHUB_USERNAME`: Usuario de Docker Hub
- `DOCKERHUB_TOKEN`: Token de acceso

### ActualizaciÃ³n de ImÃ¡genes
```bash
# Forzar actualizaciÃ³n de deployments
kubectl rollout restart deployment/api -n mlops
kubectl rollout restart deployment/frontend -n mlops
```

## ğŸ› Troubleshooting

### Pods en CrashLoopBackOff
```bash
kubectl logs <pod-name> -n mlops --previous
kubectl describe pod <pod-name> -n mlops
```

### Argo CD no sincroniza
```bash
# Hard refresh
kubectl delete application <app-name> -n argocd
kubectl apply -f infra/argocd/applications/core-apps.yaml
```

### MLflow no guarda artefactos
```bash
# Verificar buckets S3
kubectl exec -n mlops <scheduler-pod> -c scheduler -- python3 -c "
import boto3
s3 = boto3.client('s3', endpoint_url='http://seaweedfs-s3.mlops.svc:8333',
                  aws_access_key_id='any', aws_secret_access_key='any')
print([b['Name'] for b in s3.list_buckets()['Buckets']])
"
# Debe mostrar: ['airflow-logs', 'data-raw', 'mlflow-artifacts']
```

### API no carga modelo
```bash
# Verificar que hay artefactos
curl http://localhost:30800/health

# Forzar recarga
curl -X POST http://localhost:30800/reload
```

## ğŸ“š Referencias

- [K3d Documentation](https://k3d.io/)
- [Argo CD Documentation](https://argo-cd.readthedocs.io/)
- [Apache Airflow](https://airflow.apache.org/)
- [MLflow](https://mlflow.org/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://streamlit.io/)

## ğŸ‘¥ Autor

David Moreno - Proyecto Final MLOps 2025

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico.
