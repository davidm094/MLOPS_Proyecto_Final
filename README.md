# MLOps Proyecto Final - End-to-End Kubernetes Platform

Este repositorio contiene la implementaciÃ³n completa de una plataforma MLOps End-to-End desplegada sobre Kubernetes (K3d) y gestionada vÃ­a GitOps con Argo CD.

![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=for-the-badge&logo=kubernetes&logoColor=white)
![Argo CD](https://img.shields.io/badge/argo%20cd-%23ef7b4d.svg?style=for-the-badge&logo=argo&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=MLflow&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)


## ğŸ— Arquitectura

```mermaid
graph TD
    subgraph K3d_Cluster [K3d Cluster]
        subgraph Namespace_ArgoCD [Namespace: argocd]
            ArgoCD[("ğŸ™ Argo CD")]
        end
        
        subgraph Namespace_MLOps [Namespace: mlops]
            direction TB
            
            subgraph Data_Layer [Data & Storage]
                SeaweedFS[("ğŸƒ SeaweedFS (S3)")]
                PostgreSQL[("ğŸ˜ PostgreSQL")]
            end
            
            subgraph Orchestration [Orchestration & Tracking]
                Airflow[("ğŸ’¨ Airflow")]
                MLflow[("ğŸ§ª MLflow")]
            end
            
            subgraph Inference [Inference & UI]
                FastAPI[("âš¡ FastAPI")]
                Streamlit[("ğŸ–¥ï¸ Streamlit")]
            end
            
            subgraph Observability [Observability]
                Prometheus[("ğŸ”¥ Prometheus")]
                Grafana[("ğŸ“Š Grafana")]
            end
        end
    end
    
    Git[("GitHub Repo")] -->|Sync| ArgoCD
    ArgoCD -->|Deploy| Namespace_MLOps
    
    Airflow -->|Read/Write| SeaweedFS
    Airflow -->|Metadata| PostgreSQL
    Airflow -->|Track| MLflow
    
    MLflow -->|Artifacts| SeaweedFS
    MLflow -->|Metadata| PostgreSQL
    
    FastAPI -->|Load Model| MLflow
    FastAPI -->|Read| SeaweedFS
    
    Streamlit -->|Predict/Explain| FastAPI
    
    Prometheus -->|Scrape| Airflow
    Prometheus -->|Scrape| FastAPI
    Prometheus -->|Scrape| MLflow
    Grafana -->|Query| Prometheus
```

### Infraestructura
- **Kubernetes:** K3d (K3s en Docker) - Ideal para desarrollo local
- **GitOps:** Argo CD (Continuous Deployment desde Git)
- **Storage:** SeaweedFS (S3-compatible) + PostgreSQL
- **Networking:** NodePort Services
- **Observabilidad:** Prometheus + Grafana

### Componentes MLOps
- **OrquestaciÃ³n:** Apache Airflow con KubernetesExecutor y Git-Sync
  ![Airflow Dashboard](docs/airflow_dashboard.png)
- **Experiment Tracking:** MLflow (Backend: Postgres, Artifacts: SeaweedFS S3)
  ![MLflow Dashboard](docs/mlflow_dashboard.png)
- **Model Serving:** FastAPI con endpoints de predicciÃ³n y explicabilidad
- **Interpretabilidad:** SHAP TreeExplainer para explicaciones de predicciones
- **Frontend:** Streamlit con visualizaciones interactivas
  ![Frontend Dashboard](docs/frontend_dashboard.png)
- **CI/CD:** GitHub Actions para build, test y push de imÃ¡genes Docker
- **Monitoring:** Prometheus + Grafana con dashboards y alertas

## ğŸš€ Inicio RÃ¡pido

### Prerequisitos
- Docker Desktop (Windows/macOS) o Docker Engine (Linux)
- WSL2 (si estÃ¡s en Windows)
- kubectl instalado
- 8GB RAM mÃ­nimo, 16GB recomendado
- 20GB de espacio en disco

### Despliegue Automatizado

```bash
# 1. Clonar el repositorio
git clone https://github.com/davidm094/MLOPS_Proyecto_Final.git
cd MLOPS_Proyecto_Final

# 2. Dar permisos de ejecuciÃ³n a los scripts
chmod +x scripts/*.sh

# 3. Ejecutar el despliegue completo
./scripts/start_mlops.sh
```

**Tiempo estimado:** 5-7 minutos

Este script:
1. âœ… Crea un cluster K3d con puertos mapeados
2. âœ… Instala y configura Argo CD
3. âœ… Despliega toda la infraestructura (Postgres, SeaweedFS)
4. âœ… Despliega las aplicaciones MLOps (Airflow, MLflow, API, Frontend)
5. âœ… Despliega observabilidad (Prometheus, Grafana)
6. âœ… Crea buckets S3 y tablas PostgreSQL necesarias
7. âœ… Muestra las URLs de acceso y credenciales

## ğŸŒ Acceso a Servicios

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Argo CD** | http://localhost:30443 | admin / (ver comando abajo) |
| **Airflow** | http://localhost:30080 | admin / admin |
| **MLflow** | http://localhost:30500 | - |
| **API (FastAPI)** | http://localhost:30800 | - |
| **Frontend (Streamlit)** | http://localhost:30501 | - |
| **Grafana** | http://localhost:30300 | admin / admin |
| **Prometheus** | http://localhost:30090 | - |

### Obtener Password de Argo CD
```bash
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d && echo
```

## ğŸ¤– Pipeline de Machine Learning

### Flujo del DAG
```mermaid
graph LR
    Start((Start)) --> Ingest[ğŸ“¥ Ingest Data]
    Ingest --> Drift{ğŸ“‰ Check Drift}
    
    Drift -->|Yes| Train[ğŸ‹ï¸ Train Model]
    Drift -->|No| End((End))
    
    Train --> Promote{ğŸ† Promote?}
    Promote -->|Yes| Reload[ğŸ”„ Reload API]
    Promote -->|No| End
    
    Reload --> End
```

### DescripciÃ³n de Tareas

| Tarea | DescripciÃ³n |
|-------|-------------|
| `ingest_data` | Descarga datos de API externa, guarda en PostgreSQL + S3 backup |
| `check_drift` | Compara datos actuales vs referencia usando KS-test |
| `train_model` | Entrena XGBoost con Optuna, registra en MLflow con SHAP |
| `reload_api` | Notifica a la API para recargar el nuevo modelo |
| `end_pipeline` | Marca finalizaciÃ³n del pipeline |

### Modelo y Features

- **Algoritmo:** XGBoost Regressor (con fallback a HistGradientBoosting)
- **Target:** Precio de propiedades inmobiliarias
- **Hyperparameter Tuning:** Optuna (10 trials)
- **Target Transform:** Log1p para mejor distribuciÃ³n
- **Features originales:**
  - `bed` - NÃºmero de habitaciones
  - `bath` - NÃºmero de baÃ±os
  - `acre_lot` - TamaÃ±o del lote (acres)
  - `house_size` - TamaÃ±o de la casa (sqft)
- **Features engineered:**
  - `state_price_mean` - Target encoding por estado
  - `is_sold` - Indicador binario
  - `bed_bath_interaction` - bed Ã— bath
  - `size_per_bed` - house_size / (bed + 1)
  - `size_per_bath` - house_size / (bath + 1)
  - `total_rooms` - bed + bath
  - `lot_to_house_ratio` - acre_lot Ã— 43560 / house_size

### MÃ©tricas Registradas
- **RMSE:** Root Mean Squared Error
- **MAE:** Mean Absolute Error
- **RÂ²:** Coeficiente de determinaciÃ³n
- **MAPE:** Mean Absolute Percentage Error
- **CV RÂ² Mean/Std:** Cross-validation metrics

### Auto-PromociÃ³n a ProducciÃ³n
El modelo se promueve automÃ¡ticamente a "Production" si:
- RÂ² â‰¥ 0.35
- RMSE â‰¤ $700,000

## ğŸ” Explicabilidad con SHAP

### Â¿QuÃ© es SHAP?
SHAP (SHapley Additive exPlanations) es una tÃ©cnica que explica las predicciones de modelos ML asignando a cada feature un valor de importancia para cada predicciÃ³n individual.

### ImplementaciÃ³n

1. **Durante el entrenamiento:**
   - Se genera un `TreeExplainer` para XGBoost
   - Se guarda como artefacto `shap_explainer.pkl` en MLflow/S3

2. **En la API (`/explain`):**
   - Carga el explainer desde S3
   - Calcula SHAP values para la entrada
   - Retorna valores, base value y nombres de features

3. **En el Frontend:**
   - Visualiza un grÃ¡fico de barras con contribuciones
   - Muestra tabla detallada de impacto por feature
   - Indica direcciÃ³n del impacto (aumenta/disminuye precio)

### Ejemplo de Respuesta `/explain`
```json
{
  "price": 450000.0,
  "shap_values": [15000.5, -8000.2, 5000.0, 25000.8, 12000.0, ...],
  "base_value": 380000.0,
  "feature_names": ["bed", "bath", "acre_lot", "house_size", "state_price_mean", ...],
  "feature_values": [3.0, 2.0, 0.25, 1800.0, 800000.0, ...],
  "model_version": "5"
}
```

## ğŸ“Š Observabilidad

### Prometheus Metrics
La API expone mÃ©tricas en `/metrics`:
- `predictions_total` - Total de predicciones por estado y versiÃ³n
- `prediction_latency_seconds` - Histograma de latencia
- `prediction_price_dollars` - Histograma de precios predichos
- `model_loaded` - Gauge indicando si el modelo estÃ¡ cargado
- `explainer_loaded` - Gauge indicando si SHAP estÃ¡ disponible

### Grafana Dashboards
Accede a http://localhost:30300 (admin/admin) para ver:
- **MLOps API Dashboard:** Requests/sec, latencia p50/p95/p99, error rate
- **Kubernetes Dashboard:** Uso de recursos, pods, deployments

### Alertas Configuradas
- API down > 1 minuto
- Latencia p95 > 2 segundos
- Error rate > 5%
- Modelo no cargado > 2 minutos

## ğŸ—„ï¸ Almacenamiento de Datos

### PostgreSQL Tables
- `raw_data` - Datos crudos de la API externa
- `clean_data` - Datos preprocesados
- `inference_logs` - Registro de todas las predicciones
- `drift_history` - Historial de detecciÃ³n de drift
- `model_history` - Historial de modelos entrenados

### S3 Buckets (SeaweedFS)
- `mlflow-artifacts` - Artefactos de MLflow (modelos, SHAP)
- `data-raw` - Backup de datos crudos
- `airflow-logs` - Logs remotos de Airflow

## ğŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â”œâ”€â”€ dags/                 # DAGs de Airflow
â”‚   â”‚   â”‚   â”œâ”€â”€ mlops_pipeline.py # DAG principal
â”‚   â”‚   â”‚   â””â”€â”€ src/              # Scripts de ML
â”‚   â”‚   â”‚       â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”‚       â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”‚       â”œâ”€â”€ drift_detection.py
â”‚   â”‚   â”‚       â””â”€â”€ model_training.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ src/main.py           # FastAPI con /predict, /explain, /metrics
â”‚   â”‚   â”œâ”€â”€ k8s/deployment.yaml
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ src/app.py            # Streamlit con SHAP visualization
â”‚       â”œâ”€â”€ k8s/deployment.yaml
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ argocd/
â”‚   â”‚   â”œâ”€â”€ applications/
â”‚   â”‚   â”‚   â”œâ”€â”€ core-apps.yaml    # Aplicaciones principales
â”‚   â”‚   â”‚   â””â”€â”€ observability.yaml # Prometheus + Grafana
â”‚   â”‚   â””â”€â”€ install/
â”‚   â”‚       â””â”€â”€ install.yaml      # Manifiestos de Argo CD
â”‚   â””â”€â”€ manifests/
â”‚       â”œâ”€â”€ secrets/              # Kubernetes Secrets
â”‚       â”œâ”€â”€ services/             # NodePort services
â”‚       â”œâ”€â”€ setup/                # Jobs de inicializaciÃ³n
â”‚       â””â”€â”€ observability/        # Alertas y dashboards
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py               # Tests unitarios de API
â”‚   â”œâ”€â”€ test_pipeline.py          # Tests de pipeline ML
â”‚   â”œâ”€â”€ conftest.py               # Fixtures de pytest
â”‚   â”œâ”€â”€ requirements.txt          # Dependencias de tests
â”‚   â””â”€â”€ load/
â”‚       â”œâ”€â”€ locustfile.py         # Tests de carga
â”‚       â””â”€â”€ locust.conf           # ConfiguraciÃ³n de Locust
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_mlops.sh            # ğŸš€ Script principal
â”‚   â”œâ”€â”€ create_cluster.sh
â”‚   â””â”€â”€ bootstrap_argocd.sh
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yaml               # GitHub Actions CI/CD
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ DEPLOYMENT_LOG.md         # BitÃ¡cora detallada
â”‚   â”œâ”€â”€ TECHNICAL_REPORT.md       # Reporte tÃ©cnico
â”‚   â”œâ”€â”€ PROJECT_STATUS.md         # Estado del proyecto
â”‚   â””â”€â”€ references/               # Referencias y guÃ­as
â””â”€â”€ README.md
```

## ğŸ“š DocumentaciÃ³n

- [Reporte TÃ©cnico Completo](docs/TECHNICAL_REPORT.md)
- [Estado del Proyecto](docs/PROJECT_STATUS.md)
- [BitÃ¡cora de Despliegue](docs/DEPLOYMENT_LOG.md)
- [Referencias](docs/references/)

## ğŸ§ª Testing

### Tests Unitarios
```bash
# Instalar dependencias
pip install -r tests/requirements.txt

# Ejecutar tests
pytest tests/ -v --cov=apps

# Solo tests de API
pytest tests/test_api.py -v

# Solo tests de pipeline
pytest tests/test_pipeline.py -v
```

### Tests de Carga con Locust
```bash
# Instalar Locust
pip install locust

# Ejecutar con UI (acceder a http://localhost:8089)
locust -f tests/load/locustfile.py --host=http://localhost:30800

# Ejecutar headless (100 usuarios, 5 minutos)
locust -f tests/load/locustfile.py --host=http://localhost:30800 \
  --headless -u 100 -r 10 -t 5m
```

### Probar la API manualmente
```bash
# PredicciÃ³n
curl -X POST http://localhost:30800/predict \
  -H "Content-Type: application/json" \
  -d '{"bed": 3, "bath": 2, "acre_lot": 0.25, "house_size": 1800, "state": "California"}'

# ExplicaciÃ³n SHAP
curl -X POST http://localhost:30800/explain \
  -H "Content-Type: application/json" \
  -d '{"bed": 3, "bath": 2, "acre_lot": 0.25, "house_size": 1800, "state": "California"}'

# Health check
curl http://localhost:30800/health

# MÃ©tricas Prometheus
curl http://localhost:30800/metrics

# InformaciÃ³n del modelo
curl http://localhost:30800/model

# Historial de predicciones
curl http://localhost:30800/predictions/history?limit=10

# Recargar modelo
curl -X POST http://localhost:30800/reload
```

## ğŸ”„ CI/CD Pipeline

### GitHub Actions
El workflow `.github/workflows/ci.yaml` incluye:

1. **Tests:** pytest con cobertura
2. **Lint:** flake8 y black
3. **Build:** ImÃ¡genes Docker multi-stage
4. **Push:** Docker Hub con tags (sha, latest, v#)
5. **Security:** Trivy vulnerability scan
6. **Load Test:** Smoke test con Locust (en PRs)

### ConfiguraciÃ³n de Secretos
En GitHub â†’ Settings â†’ Secrets:
- `DOCKERHUB_USERNAME`: Usuario de Docker Hub
- `DOCKERHUB_TOKEN`: Token de acceso

### ActualizaciÃ³n de ImÃ¡genes
```bash
# Forzar actualizaciÃ³n de deployments
kubectl rollout restart deployment/api -n mlops
kubectl rollout restart deployment/frontend -n mlops
```

## ğŸ›  Comandos Ãštiles

### GestiÃ³n del Cluster
```bash
# Ver todos los pods
kubectl get pods -A

# Ver aplicaciones de Argo CD
kubectl get apps -n argocd

# Logs del scheduler de Airflow
kubectl logs -n mlops -l component=scheduler -c scheduler -f

# Logs de MLflow
kubectl logs -n mlops -l app.kubernetes.io/name=mlflow -f

# Detener cluster (conserva datos)
k3d cluster stop mlops-cluster

# Eliminar cluster
k3d cluster delete mlops-cluster
```

### Debugging
```bash
# Shell en un pod
kubectl exec -it <pod-name> -n mlops -- /bin/bash

# Ver eventos recientes
kubectl get events -n mlops --sort-by='.lastTimestamp' | tail -20

# Describir pod problemÃ¡tico
kubectl describe pod <pod-name> -n mlops

# Ver datos en PostgreSQL
kubectl exec -n mlops $(kubectl get pods -n mlops -l app.kubernetes.io/name=postgresql -o jsonpath="{.items[0].metadata.name}") \
  -- psql -U postgres -d mlops_data -c "SELECT COUNT(*) FROM inference_logs;"
```

## ğŸ› Troubleshooting

### Pods en CrashLoopBackOff
```bash
kubectl logs <pod-name> -n mlops --previous
kubectl describe pod <pod-name> -n mlops
```

### Argo CD no sincroniza
```bash
# Hard refresh
kubectl delete application <app-name> -n argocd
kubectl apply -f infra/argocd/applications/core-apps.yaml
```

### MLflow no guarda artefactos
```bash
# Verificar buckets S3
kubectl exec -n mlops <scheduler-pod> -c scheduler -- python3 -c "
import boto3
s3 = boto3.client('s3', endpoint_url='http://seaweedfs-s3.mlops.svc:8333',
                  aws_access_key_id='any', aws_secret_access_key='any')
print([b['Name'] for b in s3.list_buckets()['Buckets']])
"
# Debe mostrar: ['airflow-logs', 'data-raw', 'mlflow-artifacts']
```

### API no carga modelo
```bash
# Verificar que hay artefactos
curl http://localhost:30800/health

# Forzar recarga
curl -X POST http://localhost:30800/reload
```

## ğŸ“š Referencias

- [K3d Documentation](https://k3d.io/)
- [Argo CD Documentation](https://argo-cd.readthedocs.io/)
- [Apache Airflow](https://airflow.apache.org/)
- [MLflow](https://mlflow.org/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Streamlit](https://streamlit.io/)
- [Prometheus](https://prometheus.io/)
- [Grafana](https://grafana.com/)
- [Locust](https://locust.io/)

## ğŸ‘¥ Autores
Anderson Alvarado 
David Moreno 
Juan PeÃ±a

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico.
